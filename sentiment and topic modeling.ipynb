{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7ff9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim import corpora, models\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "from gensim.utils import SaveLoad\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from re import sub\n",
    "import pyLDAvis\n",
    "import nltk\n",
    "import numpy as np\n",
    "# import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "from collections import Counter\n",
    "from gensim.matutils import corpus2csc, sparse2full, corpus2dense\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.utils import resample\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e2a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75c680db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('csvfile_global_twitter_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea4532c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>original_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>user</th>\n",
       "      <th>...</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-07 22:31:20+00:00</td>\n",
       "      <td>1556407673284861952</td>\n",
       "      <td>1556407673284861952</td>\n",
       "      <td>RT @i_ameztoy: Extra random image (I):\\n\\nLets...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 143]</td>\n",
       "      <td>{'hashtags': [{'text': 'City', 'indices': [132...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>{'id': 3418339671, 'id_str': '3418339671', 'na...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>-1.250000e-01</td>\n",
       "      <td>0.190625</td>\n",
       "      <td>23</td>\n",
       "      <td>rt iameztoy extra random imag let focu one spe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>rt iameztoy extra random imag let focu one spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-07 22:31:16+00:00</td>\n",
       "      <td>1556407654373027840</td>\n",
       "      <td>1556407654373027840</td>\n",
       "      <td>RT @IndoPac_Info: #China's media explains the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 140]</td>\n",
       "      <td>{'hashtags': [{'text': 'China', 'indices': [18...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>{'id': 1003562923, 'id_str': '1003562923', 'na...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>24</td>\n",
       "      <td>rt indopacinfo china medium explain militari r...</td>\n",
       "      <td>negative</td>\n",
       "      <td>rt indopacinfo china medium explain militari r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-07 22:31:07+00:00</td>\n",
       "      <td>1556407616208773122</td>\n",
       "      <td>1556407616208773120</td>\n",
       "      <td>China even cut off communication, they don't a...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 161]</td>\n",
       "      <td>{'hashtags': [{'text': 'XiJinping', 'indices':...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>{'id': 1132320481506406400, 'id_str': '1132320...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>china even cut commun dont anwer phonecal u cl...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>china even cut commun dont anwer phonecal u cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-07 22:31:06+00:00</td>\n",
       "      <td>1556407614602461185</td>\n",
       "      <td>1556407614602461184</td>\n",
       "      <td>Putin to #XiJinping : I told you my friend, Ta...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 179]</td>\n",
       "      <td>{'hashtags': [{'text': 'XiJinping', 'indices':...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>{'id': 1132320481506406400, 'id_str': '1132320...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>33</td>\n",
       "      <td>putin xijinp tell friend taiwan vassal state i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>putin xijinp tell friend taiwan vassal state i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-07 22:31:04+00:00</td>\n",
       "      <td>1556407604238245889</td>\n",
       "      <td>1556407604238245888</td>\n",
       "      <td>RT @ChinaUncensored: I’m sorry, I thought Taiw...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 140]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>{'id': 1260798065373523969, 'id_str': '1260798...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>21</td>\n",
       "      <td>rt chinauncensor i’m sorri think taiwan indepe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>rt chinauncensor i’m sorri think taiwan indepe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at                   id               id_str  \\\n",
       "0  2022-08-07 22:31:20+00:00  1556407673284861952  1556407673284861952   \n",
       "1  2022-08-07 22:31:16+00:00  1556407654373027840  1556407654373027840   \n",
       "2  2022-08-07 22:31:07+00:00  1556407616208773122  1556407616208773120   \n",
       "3  2022-08-07 22:31:06+00:00  1556407614602461185  1556407614602461184   \n",
       "4  2022-08-07 22:31:04+00:00  1556407604238245889  1556407604238245888   \n",
       "\n",
       "                                       original_text  truncated  \\\n",
       "0  RT @i_ameztoy: Extra random image (I):\\n\\nLets...      False   \n",
       "1  RT @IndoPac_Info: #China's media explains the ...      False   \n",
       "2  China even cut off communication, they don't a...      False   \n",
       "3  Putin to #XiJinping : I told you my friend, Ta...      False   \n",
       "4  RT @ChinaUncensored: I’m sorry, I thought Taiw...      False   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0           [0, 143]  {'hashtags': [{'text': 'City', 'indices': [132...   \n",
       "1           [0, 140]  {'hashtags': [{'text': 'China', 'indices': [18...   \n",
       "2           [0, 161]  {'hashtags': [{'text': 'XiJinping', 'indices':...   \n",
       "3           [0, 179]  {'hashtags': [{'text': 'XiJinping', 'indices':...   \n",
       "4           [0, 140]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "2  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "3  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "4  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                user  ...  favorite_count  \\\n",
       "0  {'id': 3418339671, 'id_str': '3418339671', 'na...  ...               0   \n",
       "1  {'id': 1003562923, 'id_str': '1003562923', 'na...  ...               0   \n",
       "2  {'id': 1132320481506406400, 'id_str': '1132320...  ...               0   \n",
       "3  {'id': 1132320481506406400, 'id_str': '1132320...  ...               0   \n",
       "4  {'id': 1260798065373523969, 'id_str': '1260798...  ...               0   \n",
       "\n",
       "   favorited  retweeted  lang      polarity subjectivity  LENGTH  \\\n",
       "0      False      False    en -1.250000e-01     0.190625      23   \n",
       "1      False      False    en -1.000000e-01     0.100000      24   \n",
       "2      False      False    en  0.000000e+00     0.000000      26   \n",
       "3      False      False    en  1.000000e-01     0.350000      33   \n",
       "4      False      False    en -6.938894e-18     0.556250      21   \n",
       "\n",
       "                                        preprocessed  sentiment  \\\n",
       "0  rt iameztoy extra random imag let focu one spe...   negative   \n",
       "1  rt indopacinfo china medium explain militari r...   negative   \n",
       "2  china even cut commun dont anwer phonecal u cl...    neutral   \n",
       "3  putin xijinp tell friend taiwan vassal state i...   positive   \n",
       "4  rt chinauncensor i’m sorri think taiwan indepe...   negative   \n",
       "\n",
       "                                               clean  \n",
       "0  rt iameztoy extra random imag let focu one spe...  \n",
       "1  rt indopacinfo china medium explain militari r...  \n",
       "2  china even cut commun dont anwer phonecal u cl...  \n",
       "3  putin xijinp tell friend taiwan vassal state i...  \n",
       "4  rt chinauncensor i’m sorri think taiwan indepe...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53bbe1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:8: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:8: DeprecationWarning: invalid escape sequence \\d\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp/ipykernel_28336/3133919804.py:8: DeprecationWarning: invalid escape sequence \\d\n",
      "  return sub('[.:;()/!&-*@$,?^\\d+]','',myWord)\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def removePunc(myWord):\n",
    "    \"\"\"Function to remove punctuation from string inputs\"\"\"\n",
    "    if myWord is None:\n",
    "        return myWord\n",
    "    else:\n",
    "        return sub('[.:;()/!&-*@$,?^\\d+]','',myWord)\n",
    "        \n",
    "def removeAscii(myWord):\n",
    "    \"\"\"Function to remove ascii from string input\"\"\"\n",
    "    if myWord is None:\n",
    "        return myWord\n",
    "    else:\n",
    "        return str(sub(r'[^\\x00-\\x7F]+','', myWord.strip()))\n",
    "\n",
    "def lemmatize(myWord):\n",
    "    \"\"\"Function to lemmatize words\"\"\"\n",
    "    if myWord is None:\n",
    "        return myWord\n",
    "    else:\n",
    "        return str(wnl.lemmatize(myWord))\n",
    "\n",
    "def removeStopWords(myWord):\n",
    "    \"\"\"Function to remove stop words\"\"\"\n",
    "    if myWord is None:\n",
    "        return myWord\n",
    "    if myWord not in str(stopwords.words('english')):\n",
    "        return myWord\n",
    "\n",
    "def removeLinkUser(myWord):\n",
    "    \"\"\"Function to remove web addresses and twitter handles\"\"\"\n",
    "    if not myWord.startswith('@') and not myWord.startswith('http'):\n",
    "        return myWord\n",
    "\n",
    "def prepText(myWord):\n",
    "    \"\"\"Final text pre-processing function\"\"\"\n",
    "    return removeStopWords(\n",
    "        lemmatize(\n",
    "            removeAscii(\n",
    "                removePunc(\n",
    "                    removeLinkUser(\n",
    "                        myWord.lower()\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3ba5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTweetList(tweetList):\n",
    "    \"\"\"Remove stop words, lemmatize, and clean all tweets\"\"\"\n",
    "    return [[prepText(word) for word\n",
    "                in tweet.split()\n",
    "                    if prepText(word) is not None]\n",
    "                for tweet in tweetList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31a26468",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanKagTweetList = filterTweetList(data['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a9d25d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['iameztoy',\n",
       "  'extra',\n",
       "  'random',\n",
       "  'imag',\n",
       "  'let',\n",
       "  'focu',\n",
       "  'one',\n",
       "  'specif',\n",
       "  'zone',\n",
       "  'western',\n",
       "  'coast',\n",
       "  'longj',\n",
       "  'district',\n",
       "  'taichung',\n",
       "  'citi',\n",
       "  'ta'],\n",
       " ['indopacinfo',\n",
       "  'china',\n",
       "  'medium',\n",
       "  'explain',\n",
       "  'militari',\n",
       "  'reason',\n",
       "  'area',\n",
       "  'drill',\n",
       "  'taiwan',\n",
       "  'strait',\n",
       "  'read',\n",
       "  'label',\n",
       "  'pi'],\n",
       " ['china',\n",
       "  'even',\n",
       "  'cut',\n",
       "  'commun',\n",
       "  'dont',\n",
       "  'anwer',\n",
       "  'phonecal',\n",
       "  'clown',\n",
       "  'zelenskyyua',\n",
       "  'enter',\n",
       "  'stage',\n",
       "  'ask',\n",
       "  'xijinp',\n",
       "  'chang',\n",
       "  'putin',\n",
       "  'mind'],\n",
       " ['putin',\n",
       "  'xijinp',\n",
       "  'tell',\n",
       "  'friend',\n",
       "  'taiwan',\n",
       "  'vassal',\n",
       "  'state',\n",
       "  'includ',\n",
       "  'nuke',\n",
       "  'much',\n",
       "  'like',\n",
       "  'ukrainian',\n",
       "  'model',\n",
       "  'warn',\n",
       "  'take',\n",
       "  'pelosi',\n",
       "  'open',\n",
       "  'china',\n",
       "  'eye'],\n",
       " ['chinauncensor',\n",
       "  'sorri',\n",
       "  'think',\n",
       "  'taiwan',\n",
       "  'independ',\n",
       "  'countri',\n",
       "  'govern',\n",
       "  'currenc',\n",
       "  'militari',\n",
       "  'travel']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanKagTweetList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0f2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd7499fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDict(myTweetList):\n",
    "    \"\"\"Create dictionary from list of tokenized documents\"\"\"\n",
    "    return corpora.Dictionary(myTweetList)\n",
    "\n",
    "def makeCorpus(myTweetList,myDict):\n",
    "    \"\"\"Create corpus from list of tokenized documents\"\"\"\n",
    "    return [myDict.doc2bow(tweet) for tweet in myTweetList]\n",
    "\n",
    "def createLDA(myCorpus, myDictionary,myTopics=50,myPasses=10,myIterations=50,myAlpha=0.001):\n",
    "    \"\"\"LDA model call function\"\"\"\n",
    "    return models.LdaMulticore(myCorpus, id2word=myDictionary, num_topics=myTopics, passes=myPasses,\n",
    "    iterations=myIterations,alpha=myAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95b939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17ca1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create model objects\"\"\"\n",
    "kagDict   = makeDict(cleanKagTweetList)\n",
    "kagCorpus = makeCorpus(cleanKagTweetList, kagDict)\n",
    "kagLda = createLDA(kagCorpus, kagDict)\n",
    "\n",
    "\"\"\"Save model objects\"\"\"\n",
    "SaveLoad.save(kagLda,'LDAmodel')\n",
    "corpora.MmCorpus.serialize('Corpus.mm', kagCorpus)\n",
    "kagDict.save('Dictionary.dict')\n",
    "\n",
    "kagLda = SaveLoad.load('LDAmodel')\n",
    "kagDict = corpora.Dictionary.load('Dictionary.dict')\n",
    "kagCorpus = corpora.MmCorpus('Corpus.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bc511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "faa45e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\Excell-Chatbot\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "ldaViz = pyLDAvis.gensim_models.prepare(kagLda, kagCorpus, kagDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edce9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8eddea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateLdaIdx(myLdaModel, myLdaViz):\n",
    "    \"\"\"Translate lda model topics to match the topics in pyLDAvis visualization\"\"\"\n",
    "    ldaVizIdx = myLdaViz[0].index\n",
    "    return list(ldaVizIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64271b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "newIdx = translateLdaIdx(kagLda,ldaViz)\n",
    "\n",
    "def createDenseMat(myLdaModel,myCorpus,newIdx):\n",
    "    \"\"\"Transform corpus to dataframe with topics matching lda visualization\"\"\"\n",
    "    numTopics = myLdaModel.num_topics\n",
    "    myDense = corpus2dense(myLdaModel[myCorpus],numTopics)\n",
    "    myDf = pd.DataFrame(myDense)\n",
    "    mySortedDf = myDf.transpose()\n",
    "    mySortedDf = myDf.transpose()[newIdx]\n",
    "    mySortedDf.columns = ['topic' + str(i + 1) for i in range(numTopics)]\n",
    "    return mySortedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519bccd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de66435",
   "metadata": {},
   "outputs": [],
   "source": [
    "kagDf = createDenseMat(kagLda,kagCorpus,newIdx)\n",
    "\n",
    "def sortByTopicToIdx(cleanedTweetList,mySortedDf,myTopic,myTopicThresh=0.1):\n",
    "    \"\"\"Returns an index of tweets surpassing a topic value threshold\"\"\"\n",
    "    myCleanArray = np.array(cleanedTweetList)\n",
    "    srtIdx = list(mySortedDf[mySortedDf[myTopic]>myTopicThresh].index)\n",
    "    return srtIdx\n",
    "\n",
    "def sortTweetsByIdx(cleanedTweetList,srtIdx):\n",
    "    \"\"\"Returns sorted tweets as a list based on a defined sort index\"\"\"\n",
    "    myCleanArray = np.array(cleanedTweetList)\n",
    "    srtTweets = list(myCleanArray[srtIdx])\n",
    "    return srtTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facae2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedIdx = sortByTopicToIdx(cleanKagTweetList,kagDf,'topic2',myTopicThresh=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud for topic \n",
    "def makeWordCloud(cleanedTweetList,mySortedDf,myTopic,myTopicThresh=0.1):\n",
    "    \"\"\"Create word cloud of tweets passing a given threshold for a given topic\"\"\"\n",
    "    sortedIdx = sortByTopicToIdx(cleanedTweetList,mySortedDf,myTopic,myTopicThresh=0.1)\n",
    "    mySortedTweets = sortTweetsByIdx(cleanedTweetList,sortedIdx)\n",
    "    filteredWords = ' '.join([' '.join(string) for string in mySortedTweets])\n",
    "    myTopicCloud = WordCloud(max_font_size=100,scale=8).generate(filteredWords)\n",
    "    fig = plt.figure(figsize=(10,10), dpi=1600)\n",
    "    plt.imshow(myTopicCloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be seen that most tweeted words are related to war in unkraine and economic crisis.\n",
    "makeWordCloud(cleanKagTweetList,kagDf,'topic2',myTopicThresh=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e34fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
